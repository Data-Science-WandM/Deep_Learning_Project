{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import re\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_syntactic_blocstring</th>\n",
       "      <th>action_blocstring</th>\n",
       "      <th>changes_list_content_syntactic_</th>\n",
       "      <th>changes_list_action</th>\n",
       "      <th>src</th>\n",
       "      <th>userId</th>\n",
       "      <th>user_class</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>change_content_syntactic</th>\n",
       "      <th>change_action</th>\n",
       "      <th>change_change_dynamic_score</th>\n",
       "      <th>highest_change_in_content_syntactic</th>\n",
       "      <th>lowest_change_in_content_syntactic</th>\n",
       "      <th>standard_deviation_of_content_syntactic</th>\n",
       "      <th>highest_change_in_action</th>\n",
       "      <th>lowest_change_in_action</th>\n",
       "      <th>standard_deviation_of_action</th>\n",
       "      <th>diversity_action</th>\n",
       "      <th>diversity_content_syntactic</th>\n",
       "      <th>diversity_change_dynamics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmq...</td>\n",
       "      <td>rprp⚀pr□prrprrrprpprprprprprpprprprp□rprprprrr...</td>\n",
       "      <td>[0.683772233983162, 0.00647286670992131, 0.801...</td>\n",
       "      <td>{'content_syntactic': [0.683772233983162, 0.00...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>146048090</td>\n",
       "      <td>bot</td>\n",
       "      <td>274</td>\n",
       "      <td>0.556376</td>\n",
       "      <td>0.297313</td>\n",
       "      <td>1.024345</td>\n",
       "      <td>0.938307</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.275047</td>\n",
       "      <td>0.901294</td>\n",
       "      <td>0.054951</td>\n",
       "      <td>0.200933</td>\n",
       "      <td>0.653102</td>\n",
       "      <td>0.652532</td>\n",
       "      <td>0.450906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(m...</td>\n",
       "      <td>r□pr□rr□rp⚀r⚀TTTTTTT□r⚀p⚀π□p|⚀rr⚀rr⚀rr□r⚀r|⚀p⚀...</td>\n",
       "      <td>[0.0600874600144512, 0.022936062507937005, 0.0...</td>\n",
       "      <td>{'content_syntactic': [0.0600874600144512, 0.0...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>797927149856403456</td>\n",
       "      <td>bot</td>\n",
       "      <td>275</td>\n",
       "      <td>0.427565</td>\n",
       "      <td>0.484909</td>\n",
       "      <td>0.711994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.356787</td>\n",
       "      <td>0.989180</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.291316</td>\n",
       "      <td>0.707387</td>\n",
       "      <td>0.693840</td>\n",
       "      <td>0.151417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mmt)(mmt)(qt)(qt)(qt)(mqt)(qt)(t)(qt)(qt)(Em)...</td>\n",
       "      <td>r□r⚀r⚀rr□rrr□r□r⚀rrr⚀r|⚁rrrrr□rrrrrr□rpprrrp□r...</td>\n",
       "      <td>[0.4050577935998917, 0.2173762078750736, 0.181...</td>\n",
       "      <td>{'content_syntactic': [0.4050577935998917, 0.2...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>1046169889138868225</td>\n",
       "      <td>bot</td>\n",
       "      <td>277</td>\n",
       "      <td>0.442671</td>\n",
       "      <td>0.284123</td>\n",
       "      <td>1.405920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015253</td>\n",
       "      <td>0.265496</td>\n",
       "      <td>0.913974</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.204972</td>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.644029</td>\n",
       "      <td>0.297367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mmt)(mmmmmmqt)(mmmmmmmmmqt)(mmt)(mmt)(qt)(mmm...</td>\n",
       "      <td>prrpp□rrrrrrrrrrrrrr□rr□rrr□rrprrrrrrr□prrrrrr...</td>\n",
       "      <td>[0.6288092648051271, 0.17944110183186945, 1.0,...</td>\n",
       "      <td>{'content_syntactic': [0.6288092648051271, 0.1...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>1085010463128195073</td>\n",
       "      <td>bot</td>\n",
       "      <td>244</td>\n",
       "      <td>0.368786</td>\n",
       "      <td>0.419595</td>\n",
       "      <td>1.029069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111362</td>\n",
       "      <td>0.206134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.698081</td>\n",
       "      <td>0.620676</td>\n",
       "      <td>0.211830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mmmmmmmqt)|(Em)|(t)(mmqt)(mt)(mmt)|(qt)(HUqt)...</td>\n",
       "      <td>p|⚁p|⚀p□p□p□p|⚁rrrrrrrrpr□prrprr□rrrprrprrrprp...</td>\n",
       "      <td>[1.0, 1.0, 0.7298648986655512, 0.8616571072267...</td>\n",
       "      <td>{'content_syntactic': [1.0, 1.0, 0.72986489866...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>1613166488</td>\n",
       "      <td>bot</td>\n",
       "      <td>245</td>\n",
       "      <td>0.618332</td>\n",
       "      <td>0.353069</td>\n",
       "      <td>0.605766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209196</td>\n",
       "      <td>0.253005</td>\n",
       "      <td>0.849471</td>\n",
       "      <td>0.075654</td>\n",
       "      <td>0.199506</td>\n",
       "      <td>0.680286</td>\n",
       "      <td>0.766445</td>\n",
       "      <td>0.627025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        content_syntactic_blocstring  \\\n",
       "0  (mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmq...   \n",
       "1  (mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(m...   \n",
       "2  (mmt)(mmt)(qt)(qt)(qt)(mqt)(qt)(t)(qt)(qt)(Em)...   \n",
       "3  (mmt)(mmmmmmqt)(mmmmmmmmmqt)(mmt)(mmt)(qt)(mmm...   \n",
       "4  (mmmmmmmqt)|(Em)|(t)(mmqt)(mt)(mmt)|(qt)(HUqt)...   \n",
       "\n",
       "                                   action_blocstring  \\\n",
       "0  rprp⚀pr□prrprrrprpprprprprprpprprprp□rprprprrr...   \n",
       "1  r□pr□rr□rp⚀r⚀TTTTTTT□r⚀p⚀π□p|⚀rr⚀rr⚀rr□r⚀r|⚀p⚀...   \n",
       "2  r□r⚀r⚀rr□rrr□r□r⚀rrr⚀r|⚁rrrrr□rrrrrr□rpprrrp□r...   \n",
       "3  prrpp□rrrrrrrrrrrrrr□rr□rrr□rrprrrrrrr□prrrrrr...   \n",
       "4  p|⚁p|⚀p□p□p□p|⚁rrrrrrrrpr□prrprr□rrrprrprrrprp...   \n",
       "\n",
       "                     changes_list_content_syntactic_  \\\n",
       "0  [0.683772233983162, 0.00647286670992131, 0.801...   \n",
       "1  [0.0600874600144512, 0.022936062507937005, 0.0...   \n",
       "2  [0.4050577935998917, 0.2173762078750736, 0.181...   \n",
       "3  [0.6288092648051271, 0.17944110183186945, 1.0,...   \n",
       "4  [1.0, 1.0, 0.7298648986655512, 0.8616571072267...   \n",
       "\n",
       "                                 changes_list_action        src  \\\n",
       "0  {'content_syntactic': [0.683772233983162, 0.00...  astroturf   \n",
       "1  {'content_syntactic': [0.0600874600144512, 0.0...  astroturf   \n",
       "2  {'content_syntactic': [0.4050577935998917, 0.2...  astroturf   \n",
       "3  {'content_syntactic': [0.6288092648051271, 0.1...  astroturf   \n",
       "4  {'content_syntactic': [1.0, 1.0, 0.72986489866...  astroturf   \n",
       "\n",
       "                userId user_class  tweet_count  change_content_syntactic  \\\n",
       "0            146048090        bot          274                  0.556376   \n",
       "1   797927149856403456        bot          275                  0.427565   \n",
       "2  1046169889138868225        bot          277                  0.442671   \n",
       "3  1085010463128195073        bot          244                  0.368786   \n",
       "4           1613166488        bot          245                  0.618332   \n",
       "\n",
       "   change_action  change_change_dynamic_score  \\\n",
       "0       0.297313                     1.024345   \n",
       "1       0.484909                     0.711994   \n",
       "2       0.284123                     1.405920   \n",
       "3       0.419595                     1.029069   \n",
       "4       0.353069                     0.605766   \n",
       "\n",
       "   highest_change_in_content_syntactic  lowest_change_in_content_syntactic  \\\n",
       "0                             0.938307                            0.006473   \n",
       "1                             1.000000                            0.004220   \n",
       "2                             1.000000                            0.015253   \n",
       "3                             1.000000                            0.111362   \n",
       "4                             1.000000                            0.209196   \n",
       "\n",
       "   standard_deviation_of_content_syntactic  highest_change_in_action  \\\n",
       "0                                 0.275047                  0.901294   \n",
       "1                                 0.356787                  0.989180   \n",
       "2                                 0.265496                  0.913974   \n",
       "3                                 0.206134                  1.000000   \n",
       "4                                 0.253005                  0.849471   \n",
       "\n",
       "   lowest_change_in_action  standard_deviation_of_action  diversity_action  \\\n",
       "0                 0.054951                      0.200933          0.653102   \n",
       "1                 0.068479                      0.291316          0.707387   \n",
       "2                 0.045573                      0.204972          0.676182   \n",
       "3                 0.049906                      0.306818          0.698081   \n",
       "4                 0.075654                      0.199506          0.680286   \n",
       "\n",
       "   diversity_content_syntactic  diversity_change_dynamics_score  \n",
       "0                     0.652532                         0.450906  \n",
       "1                     0.693840                         0.151417  \n",
       "2                     0.644029                         0.297367  \n",
       "3                     0.620676                         0.211830  \n",
       "4                     0.766445                         0.627025  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(filename):\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "data = get_data('output_file copy.json')\n",
    "# data = get_data('./rnn/only_action_method/output_file copy.json')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data = data[~data['src'].isin(['astroturf', 'pronbots-19', 'political-bots-19'])]\n",
    "# np.unique(data['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "user_class\n",
      "bot      32041\n",
      "human    27704\n",
      "Name: count, dtype: int64\n",
      "Balanced class distribution:\n",
      "user_class\n",
      "human    27704\n",
      "bot      27704\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original class distribution:\")\n",
    "print(data['user_class'].value_counts())\n",
    "\n",
    "# Separate data by user_class\n",
    "bots = data[data['user_class'] == 'bot']\n",
    "humans = data[data['user_class'] == 'human']\n",
    "\n",
    "# Select the minimum class size\n",
    "min_class_size = min(len(bots), len(humans))\n",
    "\n",
    "# Downsample each class to the minimum class size\n",
    "bots_balanced = bots.sample(n=min_class_size, random_state=1)\n",
    "humans_balanced = humans.sample(n=min_class_size, random_state=1)\n",
    "\n",
    "# Combine the balanced classes\n",
    "balanced_data = pd.concat([bots_balanced, humans_balanced])\n",
    "\n",
    "# Shuffle the data\n",
    "balanced_data = shuffle(balanced_data, random_state=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced class distribution:\")\n",
    "print(balanced_data['user_class'].value_counts())\n",
    "\n",
    "data = balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, 'action_blocstring']\n",
    "        label = 1 if self.data.loc[idx, 'user_class'] == 'bot' else 0\n",
    "        return {\n",
    "            'text': text, \n",
    "            'label': label \n",
    "        }\n",
    "\n",
    "dataset = UserDataset(data)\n",
    "\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example usage: Iterate through the test loader\n",
    "# for batch in val_loader:\n",
    "#     print(batch['text'], batch['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 15\n",
      "vocab {'<pad>': 0, '<unk>': 1, '|': 2, 'r': 3, 'T': 4, '⚁': 5, '⚀': 6, 'p': 7, '□': 8, '⚂': 9, '⚃': 10, 'π': 11, '⚄': 12, 'ρ': 13, '⚅': 14}\n"
     ]
    }
   ],
   "source": [
    "# Counter: subclass of Python's dictionary used for counting hashable objects, in this case, tokens (words).\n",
    "# OrderedDict: subclass of Python's dictionary that remembers the insertion order of keys. It is used to store tokens in a specific order based on frequency.\n",
    "from collections import Counter, OrderedDict\n",
    "# re: A module for working with regular expressions, used to manipulate and clean text.\n",
    "import re\n",
    "\n",
    "# Token counts and vocab creation\n",
    "# Initializes an empty Counter object to hold the frequency of each token in the dataset.\n",
    "token_counts = Counter()\n",
    "\n",
    "# Define tokenizer\n",
    "def tokenizer(text):\n",
    "\n",
    "    #  replace | with \" \"\n",
    "    # text = text.replace(\"|\", \" \")\n",
    "\n",
    "    return list(text)\n",
    "\n",
    "# Tokenize the training data and populate token_counts\n",
    "for entry in train_dataset:  # Assuming train_dataset is a dataset with 'text'\n",
    "    line = entry['text']\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "# Sort tokens by frequency\n",
    "# token_counts.items() returns the tokens and their respective counts as a list of tuples (e.g., [(token1, count1), (token2, count2), ...])\n",
    "# key=lambda x: x[1] means that the sorting is based on the count (x[1]), which is the second element of each tuple\n",
    "# reverse=True means that the most frequent tokens appear first in the sorted list.\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create an ordered dictionary for the vocab\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "# The padding token (pad) is used to ensure that all sequences in a batch have the same length.\n",
    "# The unknown token (unk) is used to represent words that are not found in the model's vocabulary (the top 69021 words in your case).\n",
    "# Any word that doesn't appear in the vocabulary is replaced by the unk token during tokenization.\n",
    "# This is critical for handling unseen words during inference, where the model encounters words that were not present in the training data.\n",
    "# Create vocab dictionary with special tokens\n",
    "# Initializes the vocab dictionary with two special tokens\n",
    "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "\n",
    "for idx, (token, count) in enumerate(ordered_dict.items(), start=2):  # Start from 2 to skip the special tokens\n",
    "    vocab[token] = idx\n",
    "\n",
    "\n",
    "# Print the vocabulary size (should be 69023)\n",
    "print('Vocab-size:', len(vocab))\n",
    "print('vocab', vocab)\n",
    "# --- Rationale:\n",
    "#\n",
    "# By assigning frequent words lower indices, we can optimize memory and computational efficiency.\n",
    "# Words that appear infrequently can either be assigned higher indices (in case we want to keep them) or omitted from the vocabulary entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 9, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 14, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "# action T|⚂T|⚅T□TT□r⚀r⚀r|⚀r|⚀r□r⚀r|⚂rTT□r□r⚀r□r|⚀r⚀r⚀r\n",
    "\n",
    "# content (t)|(t)|(Et)(E)(Et)(qt)(Et)(EHUt)|(Et)|(mUt)(HHHHHHt)(qt)|(qt)(E)(Et)(mmmqt)(Et)(HUt)(Ut)|(qt)(mqt)(EHUt)\n",
    "\n",
    "# text (T -> t)|(⚂)(T -> t)|(⚅)(T -> Et)(□)(T -> E)(T -> Et)(□)(r -> qt)(⚀)(r -> Et)(⚀)(r -> EHUt)|(⚀)(r -> Et)|(⚀)(r -> mUt)(□)\n",
    "\n",
    "def encode(tokens):\n",
    "    #If the token does not exist in the vocab, the function returns the index of the <unk>\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "# Example usage\n",
    "print(encode(tokenizer('(T -> t)|(⚂)(T -> t)|(⚅)(T -> Et)(□)(T -> E)(T -> Et)(□)(r -> qt)(⚀)(r -> Et)(⚀)(r -> EHUt)|(⚀)(r -> Et)|(⚀)(r -> mUt)(□)')))  # Should output something like [11, 7, 35, 457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Use the manual vocab creation process from earlier\n",
    "# Assuming `vocab` and `tokenizer` are already defined\n",
    "\n",
    "#text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "# Updated text pipeline\n",
    "text_pipeline = lambda x: [vocab.get(token, vocab[\"<unk>\"]) for token in tokenizer(x)]\n",
    "\n",
    "label_pipeline = lambda x: float(x)  # Convert to float to match the output\n",
    "\n",
    "# Batch collation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for entry in batch:  # Each 'entry' is a dictionary with 'text' and 'label'\n",
    "        _label = entry['label']\n",
    "        _text = entry['text']\n",
    "\n",
    "        # Process labels and text\n",
    "        label_list.append(label_pipeline(_label))  # Convert labels using label_pipeline\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)  # Convert text to indices\n",
    "\n",
    "        # Store processed text and its length\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "\n",
    "    # Convert lists to tensors and pad sequences\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text batch: tensor([[ 3,  8,  7,  ...,  0,  0,  0],\n",
      "        [ 3,  6,  3,  ...,  0,  0,  0],\n",
      "        [ 7,  3,  7,  ...,  2, 12,  3],\n",
      "        [ 3,  2,  9,  ...,  0,  0,  0]])\n",
      "Label batch: tensor([1., 1., 0., 1.])\n",
      "Length batch: tensor([411, 407, 473,  75])\n",
      "Text batch shape: torch.Size([4, 473])\n"
     ]
    }
   ],
   "source": [
    "#-----  Example usage with DataLoader -----#\n",
    "## Take a small batch\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "\n",
    "# Print the output batch\n",
    "print(\"Text batch:\", text_batch)\n",
    "print(\"Label batch:\", label_batch)\n",
    "print(\"Length batch:\", length_batch)\n",
    "print(\"Text batch shape:\", text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Batching the datasets\n",
    "batch_size = 32\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers=2, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, dropout=dropout_rate)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        self.embedded_text = out.clone().detach().requires_grad_(True)  # Track embeddings for saliency\n",
    "        out = nn.utils.rnn.pack_padded_sequence(self.embedded_text, lengths.cpu().numpy(), \n",
    "                                                enforce_sorted=False, batch_first=True)\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:  # Loop through batches in dataloader\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item() * label_batch.size(0)\n",
    "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:  # Loop through batches in dataloader\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item() * label_batch.size(0)\n",
    "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with the best hyperparameters\n",
    "lr                   = 0.001\n",
    "embed_dim            = 64\n",
    "rnn_hidden_size      = 128\n",
    "fc_hidden_size       = 64\n",
    "num_layers           = 2\n",
    "dropout_rate         = 0\n",
    "\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Initialize lists to store training and validation metrics for each epoch\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "valid_accuracies = []\n",
    "valid_losses = []\n",
    "\n",
    "num_epochs = 40\n",
    "early_stop_patience = 10  # Stop training if no improvement after this many epochs\n",
    "\n",
    "best_val_loss = 10\n",
    "\n",
    "# Training loop with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    acc_train, loss_train = train_epoch(train_dl, model, optimizer, loss_fn)\n",
    "    acc_valid, loss_valid = evaluate_epoch(val_dl, model, loss_fn)\n",
    "\n",
    "    # Store metrics\n",
    "    train_accuracies.append(acc_train)\n",
    "    train_losses.append(loss_train)\n",
    "    valid_accuracies.append(acc_valid)\n",
    "    valid_losses.append(loss_valid)\n",
    "\n",
    "    print(f'Epoch {epoch + 1} - train_accuracy: {acc_train:.4f}, val_accuracy: {acc_valid:.4f}, train_loss: {loss_train:.4f}, val_loss: {loss_valid:.4f}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if loss_valid < best_val_loss:\n",
    "        best_val_loss = loss_valid\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}. Best validation loss was {best_val_loss:.4f} at epoch {best_epoch + 1}.\")\n",
    "        break\n",
    "\n",
    "# Adjust x-values to match the actual number of epochs completed\n",
    "epochs_completed = len(train_losses)  # Get the actual number of epochs completed\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot Training and Validation Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs_completed + 1), train_losses, label='Training Loss', color='red')\n",
    "plt.plot(range(1, epochs_completed + 1), valid_losses, label='Validation Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Training and Validation Accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs_completed + 1), train_accuracies, label='Training Accuracy', color='red')\n",
    "plt.plot(range(1, epochs_completed + 1), valid_accuracies, label='Validation Accuracy', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_epoch(test_dl, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "def generate_confusion_matrix(dataloader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            preds = model(text_batch, lengths)[:, 0]\n",
    "            all_preds.extend((preds >= 0.5).cpu().numpy())\n",
    "            all_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Human', 'Bot'], yticklabels=['Human', 'Bot'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Generate confusion matrix on the test dataset\n",
    "generate_confusion_matrix(test_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "\n",
    "# Vocabulary mapping\n",
    "vocab = {'<pad>': 0, '<unk>': 1, '|': 2, 'r': 3, 'T': 4, '⚁': 5, '⚀': 6, \n",
    "         'p': 7, '□': 8, '⚂': 9, '⚃': 10, 'π': 11, '⚄': 12, 'ρ': 13, '⚅': 14}\n",
    "index_to_token = {v: k for k, v in vocab.items()}\n",
    "\n",
    "#-----  Example usage with DataLoader -----#\n",
    "## Take a small batch\n",
    "\n",
    "dataloader = DataLoader(test_dataset, batch_size=20, shuffle=False, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "\n",
    "def get_saliency_map(model, text_batch, lengths, target_index=0):\n",
    "    model.eval()\n",
    "    model.rnn.train()\n",
    "    model.embedded_text.requires_grad = True\n",
    "\n",
    "    pred = model(text_batch, lengths)[:, 0]\n",
    "    predicted_label = (pred[target_index] >= 0.5).int().item()\n",
    "    confidence = pred[target_index].item()\n",
    "    print(f\"Predicted Label: {predicted_label} (Confidence: {confidence:.4f})\")\n",
    "\n",
    "    pred[target_index].backward()\n",
    "    saliency = model.embedded_text.grad.abs().sum(dim=2).squeeze(0)\n",
    "\n",
    "    model.rnn.eval()\n",
    "    return saliency, predicted_label, confidence\n",
    "\n",
    "def highlight_text(input_indices, saliency_map):\n",
    "    input_tokens = [index_to_token[idx.item()] for idx in input_indices]\n",
    "    saliency_norm = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())\n",
    "\n",
    "    highlighted_text = \"\"\n",
    "    for idx, token in enumerate(input_tokens):\n",
    "        intensity = saliency_norm[idx].item()\n",
    "        color = f'rgba(255, 0, 0, {intensity})'\n",
    "        highlighted_text += f'<span style=\"background-color: {color}; padding: 2px 4px; border-radius: 4px;\">{token}</span> '\n",
    "\n",
    "    display(HTML(f\"<div style='font-family: monospace; line-height: 1.6;'>{highlighted_text}</div>\"))\n",
    "\n",
    "# Processing 10 samples\n",
    "for i in range(20):\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    text_sample = text_batch[i].unsqueeze(0)\n",
    "    length_sample = torch.tensor([length_batch[i].item()])\n",
    "    saliency_map, predicted_label, confidence = get_saliency_map(model, text_sample, length_sample)\n",
    "\n",
    "    length = int(length_batch[i].item())  # Convert tensor to integer\n",
    "    actual_label = 'bot' if int(label_batch[i]) == 1 else 'human'  # Map 1 to 'bot' and 0 to 'human'\n",
    "    print(\"test\", predicted_label)\n",
    "    predicted_label_class = 'bot' if int(predicted_label) == 1 else 'human'  # Compare directly\n",
    "\n",
    "    # Print the required information\n",
    "    print(f\"Length of Sample {i + 1} : {length}\")\n",
    "    print(f\"Actual Label: {actual_label} | Predicted Label: {predicted_label_class}\")\n",
    "\n",
    "    # Saliency plot\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.bar(range(len(saliency_map)), saliency_map.cpu().detach().numpy())\n",
    "    plt.title(f\"Saliency Map - Sample {i + 1}\")\n",
    "    plt.xlabel(\"Token Index\")\n",
    "    plt.ylabel(\"Importance Score\")\n",
    "    plt.show()\n",
    "\n",
    "    # Highlighted Text (Raw & Decoded)\n",
    "    highlight_text(text_sample[0], saliency_map)\n",
    "\n",
    "    print(\"----------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
