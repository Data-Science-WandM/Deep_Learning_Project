{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ddc186",
   "metadata": {
    "papermill": {
     "duration": 2.033706,
     "end_time": "2024-12-14T20:12:05.050897",
     "exception": false,
     "start_time": "2024-12-14T20:12:03.017191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f43a06c9fd0>: Failed to establish a new connection: [Errno -5] No address associated with hostname')': /simple/torch/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch\n",
      "  Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/iahewababarand/.local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached torch-2.5.1-cp311-cp311-manylinux1_x86_64.whl (906.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, tqdm, sympy, requests, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, nvidia-cusolver-cu12, torch, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nwalatextutils 0.0.5 requires tldextract, which is not installed.\n",
      "sumgram 1.0.4 requires urllib3<2.0, but you have urllib3 2.2.1 which is incompatible.\n",
      "twitterbloc 1.2.2 requires urllib3<2.0, but you have urllib3 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.2.0 filelock-3.16.1 huggingface-hub-0.27.1 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 requests-2.32.3 sympy-1.13.1 torch-2.5.1 tqdm-4.67.1 triton-3.1.0 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57961ed4",
   "metadata": {
    "papermill": {
     "duration": 1.850148,
     "end_time": "2024-12-14T20:12:06.905203",
     "exception": false,
     "start_time": "2024-12-14T20:12:05.055055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import re\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a36291",
   "metadata": {
    "papermill": {
     "duration": 7.052572,
     "end_time": "2024-12-14T20:12:13.961709",
     "exception": false,
     "start_time": "2024-12-14T20:12:06.909137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_syntactic_blocstring</th>\n",
       "      <th>action_blocstring</th>\n",
       "      <th>changes_list_content_syntactic_</th>\n",
       "      <th>changes_list_action</th>\n",
       "      <th>src</th>\n",
       "      <th>userId</th>\n",
       "      <th>user_class</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>change_content_syntactic</th>\n",
       "      <th>change_action</th>\n",
       "      <th>change_change_dynamic_score</th>\n",
       "      <th>highest_change_in_content_syntactic</th>\n",
       "      <th>lowest_change_in_content_syntactic</th>\n",
       "      <th>standard_deviation_of_content_syntactic</th>\n",
       "      <th>highest_change_in_action</th>\n",
       "      <th>lowest_change_in_action</th>\n",
       "      <th>standard_deviation_of_action</th>\n",
       "      <th>diversity_action</th>\n",
       "      <th>diversity_content_syntactic</th>\n",
       "      <th>diversity_change_dynamics_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmq...</td>\n",
       "      <td>rprp⚀pr□prrprrrprpprprprprprpprprprp□rprprprrr...</td>\n",
       "      <td>[0.683772233983162, 0.00647286670992131, 0.801...</td>\n",
       "      <td>{'content_syntactic': [0.683772233983162, 0.00...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>146048090</td>\n",
       "      <td>bot</td>\n",
       "      <td>274</td>\n",
       "      <td>0.556376</td>\n",
       "      <td>0.297313</td>\n",
       "      <td>1.024345</td>\n",
       "      <td>0.938307</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.275047</td>\n",
       "      <td>0.901294</td>\n",
       "      <td>0.054951</td>\n",
       "      <td>0.200933</td>\n",
       "      <td>0.653102</td>\n",
       "      <td>0.652532</td>\n",
       "      <td>0.450906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(m...</td>\n",
       "      <td>r□pr□rr□rp⚀r⚀TTTTTTT□r⚀p⚀π□p|⚀rr⚀rr⚀rr□r⚀r|⚀p⚀...</td>\n",
       "      <td>[0.0600874600144512, 0.022936062507937005, 0.0...</td>\n",
       "      <td>{'content_syntactic': [0.0600874600144512, 0.0...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>797927149856403456</td>\n",
       "      <td>bot</td>\n",
       "      <td>275</td>\n",
       "      <td>0.427565</td>\n",
       "      <td>0.484909</td>\n",
       "      <td>0.711994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.356787</td>\n",
       "      <td>0.989180</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.291316</td>\n",
       "      <td>0.707387</td>\n",
       "      <td>0.693840</td>\n",
       "      <td>0.151417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mmt)(mmt)(qt)(qt)(qt)(mqt)(qt)(t)(qt)(qt)(Em)...</td>\n",
       "      <td>r□r⚀r⚀rr□rrr□r□r⚀rrr⚀r|⚁rrrrr□rrrrrr□rpprrrp□r...</td>\n",
       "      <td>[0.4050577935998917, 0.2173762078750736, 0.181...</td>\n",
       "      <td>{'content_syntactic': [0.4050577935998917, 0.2...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>1046169889138868225</td>\n",
       "      <td>bot</td>\n",
       "      <td>277</td>\n",
       "      <td>0.442671</td>\n",
       "      <td>0.284123</td>\n",
       "      <td>1.405920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015253</td>\n",
       "      <td>0.265496</td>\n",
       "      <td>0.913974</td>\n",
       "      <td>0.045573</td>\n",
       "      <td>0.204972</td>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.644029</td>\n",
       "      <td>0.297367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(mmt)(mmmmmmqt)(mmmmmmmmmqt)(mmt)(mmt)(qt)(mmm...</td>\n",
       "      <td>prrpp□rrrrrrrrrrrrrr□rr□rrr□rrprrrrrrr□prrrrrr...</td>\n",
       "      <td>[0.6288092648051271, 0.17944110183186945, 1.0,...</td>\n",
       "      <td>{'content_syntactic': [0.6288092648051271, 0.1...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>1085010463128195073</td>\n",
       "      <td>bot</td>\n",
       "      <td>244</td>\n",
       "      <td>0.368786</td>\n",
       "      <td>0.419595</td>\n",
       "      <td>1.029069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111362</td>\n",
       "      <td>0.206134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.698081</td>\n",
       "      <td>0.620676</td>\n",
       "      <td>0.211830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mmmmmmmqt)|(Em)|(t)(mmqt)(mt)(mmt)|(qt)(HUqt)...</td>\n",
       "      <td>p|⚁p|⚀p□p□p□p|⚁rrrrrrrrpr□prrprr□rrrprrprrrprp...</td>\n",
       "      <td>[1.0, 1.0, 0.7298648986655512, 0.8616571072267...</td>\n",
       "      <td>{'content_syntactic': [1.0, 1.0, 0.72986489866...</td>\n",
       "      <td>astroturf</td>\n",
       "      <td>1613166488</td>\n",
       "      <td>bot</td>\n",
       "      <td>245</td>\n",
       "      <td>0.618332</td>\n",
       "      <td>0.353069</td>\n",
       "      <td>0.605766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209196</td>\n",
       "      <td>0.253005</td>\n",
       "      <td>0.849471</td>\n",
       "      <td>0.075654</td>\n",
       "      <td>0.199506</td>\n",
       "      <td>0.680286</td>\n",
       "      <td>0.766445</td>\n",
       "      <td>0.627025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        content_syntactic_blocstring  \\\n",
       "0  (mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmqt)(mmmmmmmmq...   \n",
       "1  (mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(mmmmmmmqt)(m...   \n",
       "2  (mmt)(mmt)(qt)(qt)(qt)(mqt)(qt)(t)(qt)(qt)(Em)...   \n",
       "3  (mmt)(mmmmmmqt)(mmmmmmmmmqt)(mmt)(mmt)(qt)(mmm...   \n",
       "4  (mmmmmmmqt)|(Em)|(t)(mmqt)(mt)(mmt)|(qt)(HUqt)...   \n",
       "\n",
       "                                   action_blocstring  \\\n",
       "0  rprp⚀pr□prrprrrprpprprprprprpprprprp□rprprprrr...   \n",
       "1  r□pr□rr□rp⚀r⚀TTTTTTT□r⚀p⚀π□p|⚀rr⚀rr⚀rr□r⚀r|⚀p⚀...   \n",
       "2  r□r⚀r⚀rr□rrr□r□r⚀rrr⚀r|⚁rrrrr□rrrrrr□rpprrrp□r...   \n",
       "3  prrpp□rrrrrrrrrrrrrr□rr□rrr□rrprrrrrrr□prrrrrr...   \n",
       "4  p|⚁p|⚀p□p□p□p|⚁rrrrrrrrpr□prrprr□rrrprrprrrprp...   \n",
       "\n",
       "                     changes_list_content_syntactic_  \\\n",
       "0  [0.683772233983162, 0.00647286670992131, 0.801...   \n",
       "1  [0.0600874600144512, 0.022936062507937005, 0.0...   \n",
       "2  [0.4050577935998917, 0.2173762078750736, 0.181...   \n",
       "3  [0.6288092648051271, 0.17944110183186945, 1.0,...   \n",
       "4  [1.0, 1.0, 0.7298648986655512, 0.8616571072267...   \n",
       "\n",
       "                                 changes_list_action        src  \\\n",
       "0  {'content_syntactic': [0.683772233983162, 0.00...  astroturf   \n",
       "1  {'content_syntactic': [0.0600874600144512, 0.0...  astroturf   \n",
       "2  {'content_syntactic': [0.4050577935998917, 0.2...  astroturf   \n",
       "3  {'content_syntactic': [0.6288092648051271, 0.1...  astroturf   \n",
       "4  {'content_syntactic': [1.0, 1.0, 0.72986489866...  astroturf   \n",
       "\n",
       "                userId user_class  tweet_count  change_content_syntactic  \\\n",
       "0            146048090        bot          274                  0.556376   \n",
       "1   797927149856403456        bot          275                  0.427565   \n",
       "2  1046169889138868225        bot          277                  0.442671   \n",
       "3  1085010463128195073        bot          244                  0.368786   \n",
       "4           1613166488        bot          245                  0.618332   \n",
       "\n",
       "   change_action  change_change_dynamic_score  \\\n",
       "0       0.297313                     1.024345   \n",
       "1       0.484909                     0.711994   \n",
       "2       0.284123                     1.405920   \n",
       "3       0.419595                     1.029069   \n",
       "4       0.353069                     0.605766   \n",
       "\n",
       "   highest_change_in_content_syntactic  lowest_change_in_content_syntactic  \\\n",
       "0                             0.938307                            0.006473   \n",
       "1                             1.000000                            0.004220   \n",
       "2                             1.000000                            0.015253   \n",
       "3                             1.000000                            0.111362   \n",
       "4                             1.000000                            0.209196   \n",
       "\n",
       "   standard_deviation_of_content_syntactic  highest_change_in_action  \\\n",
       "0                                 0.275047                  0.901294   \n",
       "1                                 0.356787                  0.989180   \n",
       "2                                 0.265496                  0.913974   \n",
       "3                                 0.206134                  1.000000   \n",
       "4                                 0.253005                  0.849471   \n",
       "\n",
       "   lowest_change_in_action  standard_deviation_of_action  diversity_action  \\\n",
       "0                 0.054951                      0.200933          0.653102   \n",
       "1                 0.068479                      0.291316          0.707387   \n",
       "2                 0.045573                      0.204972          0.676182   \n",
       "3                 0.049906                      0.306818          0.698081   \n",
       "4                 0.075654                      0.199506          0.680286   \n",
       "\n",
       "   diversity_content_syntactic  diversity_change_dynamics_score  \n",
       "0                     0.652532                         0.450906  \n",
       "1                     0.693840                         0.151417  \n",
       "2                     0.644029                         0.297367  \n",
       "3                     0.620676                         0.211830  \n",
       "4                     0.766445                         0.627025  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(filename):\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "data = get_data('output_file copy.json')\n",
    "# data = get_data('./rnn/only_action_method/output_file copy.json')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8b8d03-76ae-42e4-a337-9f655087c990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['botometer-feedback-19', 'botwiki-19', 'celebrity-19', 'cresci-17',\n",
       "       'cresci-rtbust-19', 'cresci-stock-18', 'gilani-17', 'midterm-18',\n",
       "       'varol-17', 'vendor-purchased-19', 'verified-19'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = data[~data['src'].isin(['astroturf', 'pronbots-19', 'political-bots-19'])]\n",
    "np.unique(data['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79634415",
   "metadata": {
    "papermill": {
     "duration": 0.086332,
     "end_time": "2024-12-14T20:12:14.052311",
     "exception": false,
     "start_time": "2024-12-14T20:12:13.965979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution:\n",
      "user_class\n",
      "human    27704\n",
      "bot      16619\n",
      "Name: count, dtype: int64\n",
      "Balanced class distribution:\n",
      "user_class\n",
      "bot      16619\n",
      "human    16619\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Original class distribution:\")\n",
    "print(data['user_class'].value_counts())\n",
    "\n",
    "# Separate data by user_class\n",
    "bots = data[data['user_class'] == 'bot']\n",
    "humans = data[data['user_class'] == 'human']\n",
    "\n",
    "# Select the minimum class size\n",
    "min_class_size = min(len(bots), len(humans))\n",
    "\n",
    "# Downsample each class to the minimum class size\n",
    "bots_balanced = bots.sample(n=min_class_size, random_state=1)\n",
    "humans_balanced = humans.sample(n=min_class_size, random_state=1)\n",
    "\n",
    "# Combine the balanced classes\n",
    "balanced_data = pd.concat([bots_balanced, humans_balanced])\n",
    "\n",
    "# Shuffle the data\n",
    "balanced_data = shuffle(balanced_data, random_state=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced class distribution:\")\n",
    "print(balanced_data['user_class'].value_counts())\n",
    "\n",
    "data = balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020e57e8",
   "metadata": {
    "papermill": {
     "duration": 0.00833,
     "end_time": "2024-12-14T20:12:14.064355",
     "exception": false,
     "start_time": "2024-12-14T20:12:14.056025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (33238, 20)\n",
      "columns Index(['content_syntactic_blocstring', 'action_blocstring',\n",
      "       'changes_list_content_syntactic_', 'changes_list_action', 'src',\n",
      "       'userId', 'user_class', 'tweet_count', 'change_content_syntactic',\n",
      "       'change_action', 'change_change_dynamic_score',\n",
      "       'highest_change_in_content_syntactic',\n",
      "       'lowest_change_in_content_syntactic',\n",
      "       'standard_deviation_of_content_syntactic', 'highest_change_in_action',\n",
      "       'lowest_change_in_action', 'standard_deviation_of_action',\n",
      "       'diversity_action', 'diversity_content_syntactic',\n",
      "       'diversity_change_dynamics_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"data shape\", data.shape)\n",
    "print(\"columns\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3427022c",
   "metadata": {
    "papermill": {
     "duration": 0.035112,
     "end_time": "2024-12-14T20:12:14.103098",
     "exception": false,
     "start_time": "2024-12-14T20:12:14.067986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.loc[idx, 'action_blocstring']\n",
    "        label = 1 if self.data.loc[idx, 'user_class'] == 'bot' else 0\n",
    "        return {\n",
    "            'text': text, \n",
    "            'label': label \n",
    "        }\n",
    "\n",
    "dataset = UserDataset(data)\n",
    "\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example usage: Iterate through the test loader\n",
    "# for batch in val_loader:\n",
    "#     print(batch['text'], batch['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70600ef6",
   "metadata": {
    "papermill": {
     "duration": 1.194239,
     "end_time": "2024-12-14T20:12:15.301317",
     "exception": false,
     "start_time": "2024-12-14T20:12:14.107078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 15\n",
      "vocab {'<pad>': 0, '<unk>': 1, '|': 2, 'r': 3, 'T': 4, '⚁': 5, '⚀': 6, 'p': 7, '□': 8, '⚂': 9, '⚃': 10, 'π': 11, '⚄': 12, 'ρ': 13, '⚅': 14}\n"
     ]
    }
   ],
   "source": [
    "# Counter: subclass of Python's dictionary used for counting hashable objects, in this case, tokens (words).\n",
    "# OrderedDict: subclass of Python's dictionary that remembers the insertion order of keys. It is used to store tokens in a specific order based on frequency.\n",
    "from collections import Counter, OrderedDict\n",
    "# re: A module for working with regular expressions, used to manipulate and clean text.\n",
    "import re\n",
    "\n",
    "# Token counts and vocab creation\n",
    "# Initializes an empty Counter object to hold the frequency of each token in the dataset.\n",
    "token_counts = Counter()\n",
    "\n",
    "# Define tokenizer\n",
    "def tokenizer(text):\n",
    "\n",
    "    #  replace | with \" \"\n",
    "    # text = text.replace(\"|\", \" \")\n",
    "\n",
    "    return list(text)\n",
    "\n",
    "# Tokenize the training data and populate token_counts\n",
    "for entry in train_dataset:  # Assuming train_dataset is a dataset with 'text'\n",
    "    line = entry['text']\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "# Sort tokens by frequency\n",
    "# token_counts.items() returns the tokens and their respective counts as a list of tuples (e.g., [(token1, count1), (token2, count2), ...])\n",
    "# key=lambda x: x[1] means that the sorting is based on the count (x[1]), which is the second element of each tuple\n",
    "# reverse=True means that the most frequent tokens appear first in the sorted list.\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create an ordered dictionary for the vocab\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "\n",
    "# The padding token (pad) is used to ensure that all sequences in a batch have the same length.\n",
    "# The unknown token (unk) is used to represent words that are not found in the model's vocabulary (the top 69021 words in your case).\n",
    "# Any word that doesn't appear in the vocabulary is replaced by the unk token during tokenization.\n",
    "# This is critical for handling unseen words during inference, where the model encounters words that were not present in the training data.\n",
    "# Create vocab dictionary with special tokens\n",
    "# Initializes the vocab dictionary with two special tokens\n",
    "vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "\n",
    "for idx, (token, count) in enumerate(ordered_dict.items(), start=2):  # Start from 2 to skip the special tokens\n",
    "    vocab[token] = idx\n",
    "\n",
    "\n",
    "# Print the vocabulary size (should be 69023)\n",
    "print('Vocab-size:', len(vocab))\n",
    "print('vocab', vocab)\n",
    "# --- Rationale:\n",
    "#\n",
    "# By assigning frequent words lower indices, we can optimize memory and computational efficiency.\n",
    "# Words that appear infrequently can either be assigned higher indices (in case we want to keep them) or omitted from the vocabulary entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facd9e15",
   "metadata": {
    "papermill": {
     "duration": 0.009657,
     "end_time": "2024-12-14T20:12:15.315188",
     "exception": false,
     "start_time": "2024-12-14T20:12:15.305531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 9, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 14, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 6, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 1]\n"
     ]
    }
   ],
   "source": [
    "# action T|⚂T|⚅T□TT□r⚀r⚀r|⚀r|⚀r□r⚀r|⚂rTT□r□r⚀r□r|⚀r⚀r⚀r\n",
    "\n",
    "# content (t)|(t)|(Et)(E)(Et)(qt)(Et)(EHUt)|(Et)|(mUt)(HHHHHHt)(qt)|(qt)(E)(Et)(mmmqt)(Et)(HUt)(Ut)|(qt)(mqt)(EHUt)\n",
    "\n",
    "# text (T -> t)|(⚂)(T -> t)|(⚅)(T -> Et)(□)(T -> E)(T -> Et)(□)(r -> qt)(⚀)(r -> Et)(⚀)(r -> EHUt)|(⚀)(r -> Et)|(⚀)(r -> mUt)(□)\n",
    "\n",
    "def encode(tokens):\n",
    "    #If the token does not exist in the vocab, the function returns the index of the <unk>\n",
    "    return [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "# Example usage\n",
    "print(encode(tokenizer('(T -> t)|(⚂)(T -> t)|(⚅)(T -> Et)(□)(T -> E)(T -> Et)(□)(r -> qt)(⚀)(r -> Et)(⚀)(r -> EHUt)|(⚀)(r -> Et)|(⚀)(r -> mUt)(□)')))  # Should output something like [11, 7, 35, 457]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d60e77",
   "metadata": {
    "papermill": {
     "duration": 0.056302,
     "end_time": "2024-12-14T20:12:15.375482",
     "exception": false,
     "start_time": "2024-12-14T20:12:15.319180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print(\"Warning: this code may be very slow on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a2afca2",
   "metadata": {
    "papermill": {
     "duration": 0.010479,
     "end_time": "2024-12-14T20:12:15.390169",
     "exception": false,
     "start_time": "2024-12-14T20:12:15.379690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Use the manual vocab creation process from earlier\n",
    "# Assuming `vocab` and `tokenizer` are already defined\n",
    "\n",
    "#text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "# Updated text pipeline\n",
    "text_pipeline = lambda x: [vocab.get(token, vocab[\"<unk>\"]) for token in tokenizer(x)]\n",
    "\n",
    "label_pipeline = lambda x: float(x)  # Convert to float to match the output\n",
    "\n",
    "# Batch collation function\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for entry in batch:  # Each 'entry' is a dictionary with 'text' and 'label'\n",
    "        _label = entry['label']\n",
    "        _text = entry['text']\n",
    "\n",
    "        # Process labels and text\n",
    "        label_list.append(label_pipeline(_label))  # Convert labels using label_pipeline\n",
    "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)  # Convert text to indices\n",
    "\n",
    "        # Store processed text and its length\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "\n",
    "    # Convert lists to tensors and pad sequences\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list, batch_first=True)\n",
    "\n",
    "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "784b4a6f",
   "metadata": {
    "papermill": {
     "duration": 0.368586,
     "end_time": "2024-12-14T20:12:15.762718",
     "exception": false,
     "start_time": "2024-12-14T20:12:15.394132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text batch: tensor([[4, 2, 9,  ..., 4, 6, 3],\n",
      "        [7, 2, 5,  ..., 0, 0, 0],\n",
      "        [3, 3, 3,  ..., 0, 0, 0],\n",
      "        [4, 2, 5,  ..., 0, 0, 0]], device='cuda:0')\n",
      "Label batch: tensor([1., 0., 1., 1.], device='cuda:0')\n",
      "Length batch: tensor([602, 362, 328, 560], device='cuda:0')\n",
      "Text batch shape: torch.Size([4, 602])\n"
     ]
    }
   ],
   "source": [
    "#-----  Example usage with DataLoader -----#\n",
    "## Take a small batch\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=4, shuffle=False, collate_fn=collate_batch)\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "\n",
    "# Print the output batch\n",
    "print(\"Text batch:\", text_batch)\n",
    "print(\"Label batch:\", label_batch)\n",
    "print(\"Length batch:\", length_batch)\n",
    "print(\"Text batch shape:\", text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c68902",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-12-14T20:12:15.767155",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8469408224674022}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8455366098294884}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8684052156469408}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.683851554663992}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8581745235707121}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8684052156469408}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8290872617853561}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8489468405215647}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8461384152457372}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8100300902708124}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.6828485456369108}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8140421263791374}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.870210631895687}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8477432296890672}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8216649949849548}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.6808425275827482}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n",
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.681444332998997}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.49380339309349053}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8463482132114065}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.883046564793647}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8778726988328721}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8479124052460595}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.881241727830586}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8914691372879316}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8639152929852003}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.766213452051498}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.7020815786307304}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8926723619299723}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8817230176874022}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.884851401756708}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8640356154494044}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8552520755625075}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8926723619299723}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8672843219829142}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8883407532186259}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8613885212369149}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8964023583202984}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8800385031885453}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8014679340632896}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8909878474311154}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.6821080495728552}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8676452893755264}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8885813981470341}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8790759234749128}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8876188184334015}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8249308145830827}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8846107568282998}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8817230176874022}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8763085067982193}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8995307423896042}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8962820358560943}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8923113945373601}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.5061966069065095}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8915894597521358}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8659607748766694}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8873781735049934}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8458669233545903}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.874022379978342}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.866803032126098}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8909878474311154}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8761881843340151}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8887017206112381}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8175911442666346}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=64, fc_hidden_size=128, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8748646372277704}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.879557213331729}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8899049452532788}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8453856334977741}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8659607748766694}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.4944050054145109}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.49380339309349053}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8925520394657682}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8872578510407894}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8908675249669114}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8933942967151968}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8888220430754422}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8937552641078089}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.9002526771748285}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8919504271447479}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8929130068583805}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8990494525327879}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8453856334977741}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.895680423535074}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8988088076043798}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.897605582962339}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8729394778005054}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8935146191794008}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8973649380339309}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8983275177475635}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8965226807845025}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8927926843941764}\n",
      "Testing with lr=0.001, embed_dim=16, rnn_hidden_size=128, fc_hidden_size=128, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 16, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8828059198652388}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8298640356154494}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8618698110937312}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8779930212970761}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8918301046805439}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8953194561424618}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8582601371676092}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8458669233545903}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8601852965948743}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8771507640476477}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8639152929852003}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8893033329322585}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8847310792925039}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8745036698351583}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8924317170015642}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8844904343640958}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8986884851401756}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8983275177475635}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8799181807243412}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8582601371676092}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8730598002647094}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8733004451931176}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8986884851401756}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8806401155095657}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8810010829021778}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8456262784261822}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8935146191794008}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8902659126458909}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8858139814703405}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8810010829021778}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8860546263987487}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.9016965467452773}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8973649380339309}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8856936590061364}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8835278546504632}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8970039706413188}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8789556010107087}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8882204307544218}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.9002526771748285}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8877391408976055}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8967633257129106}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8986884851401756}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8961617133918902}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8994104199254}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8966430032487065}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.879557213331729}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.9016965467452773}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8935146191794008}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.897485260498135}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8990494525327879}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8933942967151968}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8982071952833593}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8967633257129106}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8941162315004211}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=64, fc_hidden_size=128, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 64, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8895439778606666}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8935146191794008}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8891830104680544}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.9007339670316448}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.9039826735651546}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8937552641078089}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8920707496089519}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.9003729996390326}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.893875586572013}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8953194561424618}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8937552641078089}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8964023583202984}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.9000120322464205}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8854530140777284}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.9003729996390326}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8894236553964625}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8983275177475635}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.8955601010708699}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8962820358560943}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8914691372879316}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8990494525327879}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8941162315004211}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8893033329322585}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8997713873180123}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8986884851401756}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8997713873180123}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.893875586572013}\n",
      "Testing with lr=0.001, embed_dim=32, rnn_hidden_size=128, fc_hidden_size=128, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 32, 'rnn_hidden_size': 128, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8610275538443027}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8945975213572374}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8899049452532788}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8824449524726267}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.7669353868367225}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8868968836481771}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8658404524124654}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8680062567681386}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.886656238719769}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=32, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 32, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.8927926843941764}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8855733365419324}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8862952713271568}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8826855974010348}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.8748646372277704}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.8986884851401756}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.9000120322464205}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.8451449885693659}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.3, 'val_accuracy': 0.9019371916736855}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=64, num_layers=3, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 64, 'num_layers': 3, 'dropout_rate': 0.5, 'val_accuracy': 0.9008542894958489}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0, 'val_accuracy': 0.8767897966550355}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.3, 'val_accuracy': 0.8843701118998917}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=1, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 1, 'dropout_rate': 0.5, 'val_accuracy': 0.8854530140777284}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0, 'val_accuracy': 0.859704006738058}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.3, 'val_accuracy': 0.9001323547106245}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=2, dropout_rate=0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 2, 'dropout_rate': 0.5, 'val_accuracy': 0.8589820719528336}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.001, 'embed_dim': 64, 'rnn_hidden_size': 32, 'fc_hidden_size': 128, 'num_layers': 3, 'dropout_rate': 0, 'val_accuracy': 0.883046564793647}\n",
      "Testing with lr=0.001, embed_dim=64, rnn_hidden_size=32, fc_hidden_size=128, num_layers=3, dropout_rate=0.3\n"
     ]
    }
   ],
   "source": [
    "## Batching the datasets\n",
    "batch_size = 32\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers=2, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=num_layers, \n",
    "                           batch_first=True, dropout=dropout_rate)  # Add num_layers and dropout between layers\n",
    "        self.dropout = nn.Dropout(dropout_rate)  # Explicit dropout layer\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        # Embedding Layer\n",
    "        out = self.embedding(text)\n",
    "        \n",
    "        # Pack the padded sequence\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), \n",
    "                                                enforce_sorted=False, batch_first=True)\n",
    "        \n",
    "        # LSTM Layers\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        \n",
    "        # Take the hidden state of the last layer\n",
    "        out = hidden[-1, :, :]  # Shape: (batch_size, rnn_hidden_size)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)  # Dropout for FC layer\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def train_epoch(dataloader, model, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:  # Loop through batches in dataloader\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item() * label_batch.size(0)\n",
    "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate_epoch(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:  # Loop through batches in dataloader\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item() * label_batch.size(0)\n",
    "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)\n",
    "\n",
    "# Grid search for hyperparameter tuning\n",
    "import itertools\n",
    "\n",
    "# Hyperparameter ranges\n",
    "param_grid = {\n",
    "    'lr': [0.001],\n",
    "    'embed_dim': [16, 32, 64],\n",
    "    'rnn_hidden_size': [32, 64, 128],\n",
    "    'fc_hidden_size': [32, 64, 128],\n",
    "    'num_layers': [1, 2, 3],  # Add num_layers\n",
    "    'dropout_rate': [0, 0.3, 0.5]  # Add dropout_rate\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "param_combinations = list(itertools.product(\n",
    "    param_grid['lr'],\n",
    "    param_grid['embed_dim'],\n",
    "    param_grid['rnn_hidden_size'],\n",
    "    param_grid['fc_hidden_size'],\n",
    "    param_grid['num_layers'],\n",
    "    param_grid['dropout_rate']\n",
    "))\n",
    "\n",
    "# Track results\n",
    "results = []\n",
    "\n",
    "# Grid search loop\n",
    "for lr, embed_dim, rnn_hidden_size, fc_hidden_size, num_layers, dropout_rate in param_combinations:\n",
    "    print(f\"Testing with lr={lr}, embed_dim={embed_dim}, rnn_hidden_size={rnn_hidden_size}, \"\n",
    "          f\"fc_hidden_size={fc_hidden_size}, num_layers={num_layers}, dropout_rate={dropout_rate}\")\n",
    "    \n",
    "    # Initialize model and optimizer for current hyperparameters\n",
    "    model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size, \n",
    "                num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCELoss()\n",
    "\n",
    "    # Train and evaluate for a few epochs (to save time during grid search)\n",
    "    for epoch in range(5):  # Shortened training for grid search\n",
    "        train_epoch(train_dl, model, optimizer, loss_fn)\n",
    "\n",
    "    acc_valid, _ = evaluate_epoch(val_dl, model, loss_fn)\n",
    "\n",
    "    print({\n",
    "        'lr': lr,\n",
    "        'embed_dim': embed_dim,\n",
    "        'rnn_hidden_size': rnn_hidden_size,\n",
    "        'fc_hidden_size': fc_hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'val_accuracy': acc_valid\n",
    "    })\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'lr': lr,\n",
    "        'embed_dim': embed_dim,\n",
    "        'rnn_hidden_size': rnn_hidden_size,\n",
    "        'fc_hidden_size': fc_hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'val_accuracy': acc_valid\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Find the best hyperparameter combination\n",
    "best_params = results_df.loc[results_df['val_accuracy'].idxmax()]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Save the results for future reference\n",
    "results_df.to_csv('grid_search_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc12a0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9762fbe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train with the best hyperparameters\n",
    "lr = best_params['lr']\n",
    "embed_dim = int(best_params['embed_dim'])\n",
    "rnn_hidden_size = int(best_params['rnn_hidden_size'])\n",
    "fc_hidden_size = int(best_params['fc_hidden_size'])\n",
    "\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Initialize lists to store training and validation metrics for each epoch\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "valid_accuracies = []\n",
    "valid_losses = []\n",
    "\n",
    "num_epochs = 20\n",
    "early_stop_patience = 10  # Stop training if no improvement after this many epochs\n",
    "\n",
    "# Training loop with early stopping\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    acc_train, loss_train = train_epoch(train_dl, model, optimizer, loss_fn)\n",
    "    acc_valid, loss_valid = evaluate_epoch(val_dl, model, loss_fn)\n",
    "\n",
    "    # Store metrics\n",
    "    train_accuracies.append(acc_train)\n",
    "    train_losses.append(loss_train)\n",
    "    valid_accuracies.append(acc_valid)\n",
    "    valid_losses.append(loss_valid)\n",
    "\n",
    "    print(f'Epoch {epoch + 1} - train_accuracy: {acc_train:.4f}, val_accuracy: {acc_valid:.4f}, train_loss: {loss_train:.4f}, val_loss: {loss_valid:.4f}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if loss_valid < best_val_loss:\n",
    "        best_val_loss = loss_valid\n",
    "        best_epoch = epoch\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f\"Early stopping at epoch {epoch + 1}. Best validation loss was {best_val_loss:.4f} at epoch {best_epoch + 1}.\")\n",
    "        break\n",
    "\n",
    "# Plotting training and validation losses\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting training and validation accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, num_epochs + 1), valid_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('images/lstm-action-accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f46e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "def generate_confusion_matrix(dataloader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            preds = model(text_batch, lengths)[:, 0]\n",
    "            all_preds.extend((preds >= 0.5).cpu().numpy())\n",
    "            all_labels.extend(label_batch.cpu().numpy())\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Human', 'Bot'], yticklabels=['Human', 'Bot'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Generate confusion matrix on the test dataset\n",
    "generate_confusion_matrix(test_dl, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "lstm-action-Copy5.ipynb",
   "output_path": "lstm-action-Copy5-pipeline.ipynb",
   "parameters": {},
   "start_time": "2024-12-14T20:12:02.107022",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
